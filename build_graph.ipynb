{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# grab a pre-trained basic model from sentenceTransformer (sentence BERT)\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sentence: This framework generates embeddings for each input sentence\nEmbedding: (768,) <class 'numpy.ndarray'>\n\nSentence: Sentences are passed as a list of string.\nEmbedding: (768,) <class 'numpy.ndarray'>\n\nSentence: The quick brown fox jumps over the lazy dog.\nEmbedding: (768,) <class 'numpy.ndarray'>\n\nSentence: hello world!!\nEmbedding: (768,) <class 'numpy.ndarray'>\n\n"
    }
   ],
   "source": [
    "# A quick test to see how our model is doing\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "            'Sentences are passed as a list of string.', \n",
    "            'The quick brown fox jumps over the lazy dog.',\n",
    "            'hello world!!']\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding.shape, type(embedding))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "source": [
    "## Examine the Quora Duplicate Question Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# create the Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# create the Spark Context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "data_path = \"quora_duplicate_questions.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "take some sample data\n+---+----+----+---------------------+--------------------+------------+\n| id|qid1|qid2|            question1|           question2|is_duplicate|\n+---+----+----+---------------------+--------------------+------------+\n|  0|   1|   2| What is the step ...|What is the step ...|           0|\n|  1|   3|   4| What is the story...|What would happen...|           0|\n|  2|   5|   6| How can I increas...|How can Internet ...|           0|\n|  3|   7|   8| Why am I mentally...|Find the remainde...|           0|\n|  4|   9|  10| Which one dissolv...|Which fish would ...|           0|\n|  5|  11|  12| Astrology: I am a...|I'm a triple Capr...|           1|\n|  6|  13|  14|  Should I buy tiago?|What keeps childe...|           0|\n|  7|  15|  16| How can I be a go...|What should I do ...|           1|\n|  8|  17|  18|When do you use シ...|\"When do you use ...|           0|\n|  9|  19|  20| Motorola (company...|How do I hack Mot...|           0|\n| 10|  21|  22| Method to find se...|What are some of ...|           0|\n| 11|  23|  24| How do I read and...|How can I see all...|           1|\n| 12|  25|  26| What can make Phy...|How can you make ...|           1|\n| 13|  27|  28| What was your fir...|What was your fir...|           1|\n| 14|  29|  30| What are the laws...|What are the laws...|           0|\n| 15|  31|  32| What would a Trum...|How will a Trump ...|           1|\n| 16|  33|  34| What does manipul...|What does manipul...|           1|\n| 17|  35|  36| Why do girls want...|How do guys feel ...|           0|\n| 18|  37|  38| Why are so many Q...|Why do people ask...|           1|\n| 19|  39|  40| Which is the best...|Which is the best...|           0|\n+---+----+----+---------------------+--------------------+------------+\nonly showing top 20 rows\n\n"
    }
   ],
   "source": [
    "curr_data = spark.read.csv(data_path, header=True, sep = '\\t')\n",
    "curr_data = curr_data.withColumn('qid1', col('qid1').cast(\"Int\"))\n",
    "curr_data = curr_data.withColumn('qid2', col('qid2').cast(\"Int\"))\n",
    "curr_data = curr_data.withColumn('id', col('id').cast(\"Int\"))\n",
    "# for some reasons, the database contains empty lines... use filter to get rid of those\n",
    "curr_data = curr_data.na.drop()\n",
    "print(\"take some sample data\")\n",
    "curr_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "num of total question pairs 404275\ntotal unique questions 537915\n"
    }
   ],
   "source": [
    "print(\"num of total question pairs\", curr_data.select('id').distinct().count())\n",
    "# build a dictionary: question_id -> question_text\n",
    "left_questions = {i[0]: i[1] for i in curr_data.select('qid1', 'question1').collect()}\n",
    "right_questions = {i[0]: i[1] for i in curr_data.select('qid2', 'question2').collect()}\n",
    "all_questions = {**left_questions, **right_questions}  # combine two dictinoaries together\n",
    "print('total unique questions', len(all_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "537933 1 537915\n"
    }
   ],
   "source": [
    "# NOTE: the question pair ids seems to contain holes, i.e. not consecutive\n",
    "print(max(all_questions.keys()), min(all_questions.keys()), len(all_questions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Questions into feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(1, 'What is the step by step guide to invest in share market in india?'),\n (2, 'What is the step by step guide to invest in share market?'),\n (3, 'What is the story of Kohinoor (Koh-i-Noor) Diamond?')]"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "all_question_list = sorted(all_questions.items(), key=lambda x: x[0])\n",
    "all_question_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Batches: 100%|██████████| 67240/67240 [18:11<00:00, 61.60it/s]\n"
    }
   ],
   "source": [
    "# output, a list of vectors, each of size [786,]\n",
    "# NOTE: Skip this cell and the next if you want to directly load the feature vectors from the disk\n",
    "feature_vec = model.encode([i[1] for i in all_question_list], show_progress_bar=True, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be able to store the feature_vec to disk\n",
    "import pickle\n",
    "with open('feature_vec.pickle', 'wb') as handle:\n",
    "    pickle.dump(feature_vec, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be able to load the feature_vec from disk\n",
    "import pickle\n",
    "with open('feature_vec.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build a graph\n",
    "# You should be able to use the index of each feature_vec, which has the same corresponding indexes in all_question_list"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit6408c2d109594dcb8ac6cdc72f57765b",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}